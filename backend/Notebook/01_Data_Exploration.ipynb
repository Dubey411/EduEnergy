{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54466be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ad858",
   "metadata": {},
   "source": [
    "## Collecting Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74b09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All raw datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "plant1_gen = pd.read_csv(\"../data/raw/Plant_1_Generation_Data.csv\")\n",
    "plant1_weather = pd.read_csv(\"../data/raw/Plant_1_Weather_Sensor_Data.csv\")\n",
    "\n",
    "plant2_gen = pd.read_csv(\"../data/raw/Plant_2_Generation_Data.csv\")\n",
    "plant2_weather = pd.read_csv(\"../data/raw/Plant_2_Weather_Sensor_Data.csv\")\n",
    "\n",
    "print(\"✅ All raw datasets loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a44590",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6e2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant1\n",
    "plant1_gen.dropna(inplace=True)\n",
    "plant1_weather.dropna(inplace=True)\n",
    "\n",
    "plant1_gen.drop_duplicates(inplace=True)\n",
    "plant1_weather.drop_duplicates(inplace=True)\n",
    "\n",
    "plant1_gen['DATE_TIME'] = pd.to_datetime(plant1_weather['DATE_TIME'])\n",
    "plant1_weather['DATE_TIME'] = pd.to_datetime(plant1_gen['DATE_TIME'])\n",
    "\n",
    "\n",
    "# Plant2\n",
    "plant2_gen.dropna(inplace=True)\n",
    "plant2_weather.dropna(inplace=True)\n",
    "\n",
    "plant2_gen.drop_duplicates(inplace=True)\n",
    "plant1_weather.drop_duplicates(inplace=True)\n",
    "\n",
    "plant2_gen['DATE_TIME'] = pd.to_datetime(plant2_weather['DATE_TIME'])\n",
    "plant2_weather['DATE_TIME'] = pd.to_datetime(plant2_gen['DATE_TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef758dd",
   "metadata": {},
   "source": [
    "## Merge Generation + Weather Data (per Plant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5864a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plant1_merged = pd.merge(plant1_gen, plant1_weather, on='DATE_TIME', how='inner')\n",
    "plant2_merged = pd.merge(plant2_gen, plant2_weather, on='DATE_TIME', how='inner')\n",
    "\n",
    "# Save processed versions\n",
    "plant1_merged.to_csv(\"../data/processed/Plant_1_Final.csv\", index=False)\n",
    "plant2_merged.to_csv(\"../data/processed/Plant_2_Final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ab3bc",
   "metadata": {},
   "source": [
    "## Combine Both Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "784f35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([plant1_merged,plant2_merged],ignore_index=True)\n",
    "combined_df.to_csv(\"../data/processed/Combined_Solar_Data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4dc6d4",
   "metadata": {},
   "source": [
    "## Preprocess Final Data for ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14a7c432",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abdac96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['DATE_TIME'] = pd.to_datetime(combined_df['DATE_TIME'])\n",
    "combined_df['HOUR'] = combined_df['DATE_TIME'].dt.hour\n",
    "combined_df['DAY_OF_YEAR'] = combined_df['DATE_TIME'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207ee85",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908649fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m X = combined_df[features]\n\u001b[32m      5\u001b[39m y = combined_df[target]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "features = ['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION', 'HOUR', 'DAY_OF_YEAR']\n",
    "target = 'DC_POWER'\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7b901",
   "metadata": {},
   "source": [
    "## Train ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94683207",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m scaler = \u001b[43mStandardScaler\u001b[49m()\n\u001b[32m      2\u001b[39m X_train_scaled = scaler.fit_transform(X_train)\n\u001b[32m      3\u001b[39m X_test_scaled = scaler.transform(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"✅ R2 Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aafb9fa",
   "metadata": {},
   "source": [
    "## Saving ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3ddf481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and Scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, \"../models/model.pkl\")\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")\n",
    "\n",
    "print(\"✅ Model and Scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be11c0",
   "metadata": {},
   "source": [
    "## Predict and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576ea5da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model = joblib.load(\u001b[33m\"\u001b[39m\u001b[33m../models/model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m scaler = joblib.load(\u001b[33m\"\u001b[39m\u001b[33m../models/scaler.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m new_data = \u001b[43mpd\u001b[49m.DataFrame({\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAMBIENT_TEMPERATURE\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m28\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m35\u001b[39m, \u001b[32m37\u001b[39m, \u001b[32m39\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMODULE_TEMPERATURE\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m40\u001b[39m, \u001b[32m42\u001b[39m, \u001b[32m45\u001b[39m, \u001b[32m48\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m53\u001b[39m],\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mIRRADIATION\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m500\u001b[39m, \u001b[32m650\u001b[39m, \u001b[32m800\u001b[39m, \u001b[32m950\u001b[39m, \u001b[32m1000\u001b[39m, \u001b[32m1050\u001b[39m],\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHOUR\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m8\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m14\u001b[39m, \u001b[32m16\u001b[39m, \u001b[32m18\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDAY_OF_YEAR\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m210\u001b[39m]*\u001b[32m6\u001b[39m\n\u001b[32m     10\u001b[39m })\n\u001b[32m     12\u001b[39m scaled_data = scaler.transform(new_data)\n\u001b[32m     13\u001b[39m predictions = model.predict(scaled_data)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = joblib.load(\"../models/model.pkl\")\n",
    "scaler = joblib.load(\"../models/scaler.pkl\")\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'AMBIENT_TEMPERATURE': [28, 30, 32, 35, 37, 39],\n",
    "    'MODULE_TEMPERATURE': [40, 42, 45, 48, 50, 53],\n",
    "    'IRRADIATION': [500, 650, 800, 950, 1000, 1050],\n",
    "    'HOUR': [8, 10, 12, 14, 16, 18],\n",
    "    'DAY_OF_YEAR': [210]*6\n",
    "})\n",
    "\n",
    "scaled_data = scaler.transform(new_data)\n",
    "predictions = model.predict(scaled_data)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(new_data['HOUR'], predictions, marker='o', color='orange')\n",
    "plt.title(\"☀️ Predicted Solar Power Generation vs Time of Day\")\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Predicted DC Power (kW)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61dc028f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load model and scaler\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./models/model.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m scaler = joblib.load(\u001b[33m\"\u001b[39m\u001b[33m./models/scaler.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Internships\\SolarPredict\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './models/model.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load model and scaler\n",
    "model = joblib.load(\"./models/model.pkl\")\n",
    "scaler = joblib.load(\"./models/scaler.pkl\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/solar_data.csv\")\n",
    "\n",
    "# Define features and target\n",
    "features = ['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION', 'HOUR', 'DAY_OF_YEAR']\n",
    "target = 'DC_POWER'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Scale features\n",
    "X_scaled = scaler.transform(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
